import requests
from datetime import datetime, timedelta
from typing import List, Dict
import re

class NewsCrawler:
    """ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰"""
    
    def __init__(self, client_id=None, client_secret=None):
        self.client_id = client_id
        self.client_secret = client_secret
        self.base_url = "https://openapi.naver.com/v1/search/news.json"
    
    def search_news(self, keyword, display=20):
        """ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰"""
        if self.client_id and self.client_secret:
            return self._search_with_api(keyword, display)
        else:
            return self._search_with_crawl(keyword, display)
    
    def _search_with_api(self, keyword, display):
        """ë„¤ì´ë²„ APIë¡œ ê²€ìƒ‰"""
        try:
            headers = {
                'X-Naver-Client-Id': self.client_id,
                'X-Naver-Client-Secret': self.client_secret
            }
            
            params = {
                'query': keyword,
                'display': min(display, 100),
                'sort': 'date'
            }
            
            response = requests.get(self.base_url, headers=headers, params=params, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            articles = []
            
            for item in data.get('items', []):
                article = {
                    'title': self._clean_html(item['title']),
                    'description': self._clean_html(item['description']),
                    'link': item.get('originallink') or item['link'],
                    'pubDate': self._parse_date(item['pubDate']),
                    'source': 'ë„¤ì´ë²„ ë‰´ìŠ¤'
                }
                articles.append(article)
            
            print(f"ğŸ“° ë„¤ì´ë²„ API: {len(articles)}ê°œ ê¸°ì‚¬ ë°œê²¬")
            return articles
            
        except Exception as e:
            print(f"âš ï¸  ë„¤ì´ë²„ API ì‹¤íŒ¨: {e}")
            return self._search_with_crawl(keyword, display)
    
    def _search_with_crawl(self, keyword, display):
        """ì›¹ í¬ë¡¤ë§ìœ¼ë¡œ ê²€ìƒ‰"""
        try:
            from bs4 import BeautifulSoup
            
            url = "https://search.naver.com/search.naver"
            params = {
                'where': 'news',
                'query': keyword,
                'sort': 0,
                'start': 1
            }
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get(url, params=params, headers=headers, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            articles = []
            
            news_items = soup.select('.news_area')
            
            for item in news_items[:display]:
                try:
                    title_elem = item.select_one('.news_tit')
                    if not title_elem:
                        continue
                    
                    title = title_elem.get_text(strip=True)
                    link = title_elem.get('href', '')
                    
                    desc_elem = item.select_one('.news_dsc')
                    description = desc_elem.get_text(strip=True) if desc_elem else ''
                    
                    info_elem = item.select_one('.info')
                    source = info_elem.get_text(strip=True) if info_elem else 'ë‰´ìŠ¤'
                    
                    article = {
                        'title': title,
                        'description': description,
                        'link': link,
                        'pubDate': datetime.now(),
                        'source': source
                    }
                    articles.append(article)
                    
                except Exception:
                    continue
            
            print(f"ğŸ“° ì›¹ í¬ë¡¤ë§: {len(articles)}ê°œ ê¸°ì‚¬ ë°œê²¬")
            return articles
            
        except Exception as e:
            print(f"âŒ ì›¹ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            return []
    
    def filter_recent(self, articles, hours=1):
        """ìµœê·¼ Nì‹œê°„ ë‚´ ê¸°ì‚¬ë§Œ í•„í„°ë§"""
        cutoff = datetime.now() - timedelta(hours=hours)
        recent = []
        
        for article in articles:
            pub_date = article.get('pubDate')
            if isinstance(pub_date, datetime) and pub_date > cutoff:
                recent.append(article)
        
        print(f"â° ìµœê·¼ {hours}ì‹œê°„ ë‚´: {len(recent)}ê°œ")
        return recent
    
    def _clean_html(self, text):
        """HTML íƒœê·¸ ì œê±°"""
        text = re.sub('<[^<]+?>', '', text)
        text = text.replace('&quot;', '"')
        text = text.replace('&apos;', "'")
        text = text.replace('&amp;', '&')
        text = text.replace('&lt;', '<')
        text = text.replace('&gt;', '>')
        return text.strip()
    
    def _parse_date(self, date_str):
        """ë‚ ì§œ ë¬¸ìì—´ì„ datetimeìœ¼ë¡œ ë³€í™˜"""
        try:
            from email.utils import parsedate_to_datetime
            return parsedate_to_datetime(date_str)
        except:
            return datetime.now()
